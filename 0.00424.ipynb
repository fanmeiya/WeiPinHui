{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-06-08T13:59:27.077913Z",
     "iopub.status.busy": "2023-06-08T13:59:27.077134Z",
     "iopub.status.idle": "2023-06-08T13:59:27.315846Z",
     "shell.execute_reply": "2023-06-08T13:59:27.314710Z",
     "shell.execute_reply.started": "2023-06-08T13:59:27.077871Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-06-08T13:59:27.319368Z",
     "iopub.status.busy": "2023-06-08T13:59:27.318841Z",
     "iopub.status.idle": "2023-06-08T13:59:27.563422Z",
     "shell.execute_reply": "2023-06-08T13:59:27.562170Z",
     "shell.execute_reply.started": "2023-06-08T13:59:27.319331Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-06-08T13:59:27.565093Z",
     "iopub.status.busy": "2023-06-08T13:59:27.564727Z",
     "iopub.status.idle": "2023-06-08T13:59:30.893479Z",
     "shell.execute_reply": "2023-06-08T13:59:30.892113Z",
     "shell.execute_reply.started": "2023-06-08T13:59:27.565062Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/external-libraries\": 文件已存在\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting beautifulsoup4\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/57/f4/a69c20ee4f660081a7dedb1ac57f29be9378e04edfcb90c526b923d4bebc/beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting soupsieve>1.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/49/37/673d6490efc51ec46d198c75903d99de59baffdd47aea3d071b80a9e4e89/soupsieve-2.4.1-py3-none-any.whl (36 kB)\r\n",
      "Installing collected packages: soupsieve, beautifulsoup4\r\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-06-08T13:59:30.896152Z",
     "iopub.status.busy": "2023-06-08T13:59:30.895382Z",
     "iopub.status.idle": "2023-06-08T13:59:30.900695Z",
     "shell.execute_reply": "2023-06-08T13:59:30.899886Z",
     "shell.execute_reply.started": "2023-06-08T13:59:30.896107Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T13:59:30.902541Z",
     "iopub.status.busy": "2023-06-08T13:59:30.902076Z",
     "iopub.status.idle": "2023-06-08T13:59:57.495713Z",
     "shell.execute_reply": "2023-06-08T13:59:57.494747Z",
     "shell.execute_reply.started": "2023-06-08T13:59:30.902502Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\r\n",
      "  mask |= (ar1 == a)\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# @FileName  :demo4.py\n",
    "# @Time      :2023/6/2 15:38\n",
    "# @Author    :FMY\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = pd.read_csv('data1.csv',index_col=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T13:59:57.497463Z",
     "iopub.status.busy": "2023-06-08T13:59:57.496900Z",
     "iopub.status.idle": "2023-06-08T14:00:00.056697Z",
     "shell.execute_reply": "2023-06-08T14:00:00.055702Z",
     "shell.execute_reply.started": "2023-06-08T13:59:57.497432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "postive_user =  data.groupby('user_id').agg({\n",
    "    'is_order': 'sum'\n",
    "    })\n",
    "postive_user = postive_user.reset_index()\n",
    "postive_user.columns=[\n",
    "    'user_id',\n",
    "    'order_sum',\n",
    "]\n",
    "postive_user =postive_user[postive_user['order_sum']>0]\n",
    "data = data[data['user_id'].isin(postive_user['user_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T14:00:00.058639Z",
     "iopub.status.busy": "2023-06-08T14:00:00.058093Z",
     "iopub.status.idle": "2023-06-08T14:00:02.031120Z",
     "shell.execute_reply": "2023-06-08T14:00:02.029941Z",
     "shell.execute_reply.started": "2023-06-08T14:00:00.058600Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['dt','expose_start_time','time_slot1','cat_id','brandsn','goods_clk_sum',\n",
    "'goods_like_sum','brandsn_addcart_sum','brandsn_order_sum','is_like',\n",
    "'cat_like_sum','cat_clk_sum','cat_order_sum','brandsn_like_sum','brandsn_clk_sum'],axis=1)\n",
    "# print('原始数据大小',data.shape)\n",
    "test = pd.read_excel('./a榜需要预测的uid_5000.xlsx',names=['user_id'])\n",
    "test = pd.merge(test,data,on=['user_id'])\n",
    "\n",
    "\n",
    "train = data\n",
    "\n",
    "train1 = train.drop(['is_order','user_id','goods_id'],axis=1)\n",
    "test1 = test.drop(['is_order','user_id','goods_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T14:00:02.035700Z",
     "iopub.status.busy": "2023-06-08T14:00:02.032358Z",
     "iopub.status.idle": "2023-06-08T14:00:02.207457Z",
     "shell.execute_reply": "2023-06-08T14:00:02.206407Z",
     "shell.execute_reply.started": "2023-06-08T14:00:02.035654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = np.array(train['is_order'].values)\n",
    "# y = y.reshape((len(y),1))\n",
    "# print('去除测试集客户后的大小',train.shape)\n",
    "test1 = np.array(test1)\n",
    "train1 = np.array(train1)\n",
    "\n",
    "\n",
    "m1 = int(0.8*len(train1))\n",
    "x_t = train1[:m1,:]\n",
    "y_t = y[:m1]\n",
    "x_t1 = train1[m1:,:]\n",
    "y_t1 = y[m1:]\n",
    "#50 ->0.507\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T14:00:02.209920Z",
     "iopub.status.busy": "2023-06-08T14:00:02.208990Z",
     "iopub.status.idle": "2023-06-08T14:00:28.892740Z",
     "shell.execute_reply": "2023-06-08T14:00:28.891746Z",
     "shell.execute_reply.started": "2023-06-08T14:00:02.209877Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(n_jobs=-1,n_estimators=70)\n",
    "model = randomForest.fit(x_t, y_t)\n",
    "y_pre = model.predict(test1)\n",
    "# accuracy = f1_score(y_t1,y_pre)\n",
    "# print('随机森林',accuracy)\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_test1 = {\"n_estimators\":range(1,101,10)}\n",
    "# gsearch1 = GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1),param_grid=param_test1,\n",
    "#                         scoring='f1',cv=10)\n",
    "# gsearch1.fit(train1, y)\n",
    "\n",
    "\n",
    "# means =gsearch1.cv_results_['mean_test_score']\n",
    "# params = gsearch1.cv_results_['params']\n",
    "# for mean,param in zip(means,params):\n",
    "#     print(\"%f  with:   %r\" % (mean,param))\n",
    " \n",
    "\n",
    "# log1 = LogisticRegression(max_iter=500)\n",
    "# model = log1.fit(x_t, y_t)\n",
    "# y_pre = model.predict(x_t1)\n",
    "# accuracy = f1_score(y_t1,y_pre)\n",
    "# print('逻辑回归',accuracy)\n",
    "\n",
    "# decisiontree = DecisionTreeClassifier()\n",
    "# model = decisiontree.fit(x_t, y_t)\n",
    "# y_pre = model.predict(x_t1)\n",
    "# accuracy = f1_score(y_t1,y_pre)\n",
    "# print('决策树',accuracy)\n",
    "\n",
    "res = {'user_id':test['user_id'].values,'goods_id':test['goods_id'].values,'order':y_pre}\n",
    "df = pd.DataFrame(res)\n",
    "df = df[df['order']==1]\n",
    "df = df.drop(columns=['order'])\n",
    "df.to_csv('u2i.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T01:53:04.664842Z",
     "iopub.status.busy": "2023-06-09T01:53:04.664168Z",
     "iopub.status.idle": "2023-06-09T01:55:59.375645Z",
     "shell.execute_reply": "2023-06-09T01:55:59.374100Z",
     "shell.execute_reply.started": "2023-06-09T01:53:04.664799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# @FileName  :demo1.py\n",
    "# @Time      :2023/6/7 16:18\n",
    "# @Author    :FMY\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('allData.csv')\n",
    "df = df.drop(['dt'], axis=1)\n",
    "df['date'] = pd.to_datetime(df['expose_start_time'])\n",
    "\n",
    "date_7_start = '2023-02-25'\n",
    "date_7_start = datetime.strptime(date_7_start, '%Y-%m-%d')\n",
    "date_7_end = '2023-03-03'\n",
    "date_7_end = datetime.strptime(date_7_end, '%Y-%m-%d')\n",
    "# date_14_start = '2023-02-18'\n",
    "# date_14_start = datetime.strptime(date_14_start, '%Y-%m-%d')\n",
    "# date_14_end = '2023-02-24'\n",
    "# date_14_end = datetime.strptime(date_14_end, '%Y-%m-%d')\n",
    "# date_21_start = '2023-02-03'\n",
    "# date_21_start = datetime.strptime(date_21_start, '%Y-%m-%d')\n",
    "# date_21_end = '2023-02-17'\n",
    "# date_21_end = datetime.strptime(date_21_end, '%Y-%m-%d')\n",
    "\n",
    "# 筛选出每个商品距离2023.3.4最近的7天的数据\n",
    "mask = (df['date'] >= date_7_start) & (df['date'] <= date_7_end)\n",
    "recent7_data = df.loc[mask]\n",
    "# # # 筛选出每个商品距离2023.3.4最近的14天的数据\n",
    "# mask = (df['date'] >= date_14_start) & (df['date'] <= date_14_end)\n",
    "# recent14_data = df.loc[mask]\n",
    "# # # 筛选出每个商品距离2023.3.4最近的21天的数据\n",
    "# mask = (df['date'] >= date_21_start) & (df['date'] <= date_21_end)\n",
    "# recent21_data = df.loc[mask]\n",
    "\n",
    "goods7_feat= recent7_data.groupby(['user_id', 'goods_id']).agg({\n",
    "    'is_clk': ['sum'],\n",
    "    'is_like': ['sum'],\n",
    "    'is_addcart': ['sum'],\n",
    "    'is_order': ['sum']\n",
    "})\n",
    "goods7_feat = goods7_feat.reset_index()\n",
    "goods7_feat.columns = [\n",
    "    'user_id',\n",
    "    'goods_id',\n",
    "    'goods_7clk',\n",
    "    'goods_7like',\n",
    "    'goods_7addcart',\n",
    "    'goods_7order'\n",
    "]\n",
    "# goods14_feat= recent14_data.groupby(['user_id', 'goods_id']).agg({\n",
    "#     'is_clk': ['sum'],\n",
    "#     'is_like': ['sum'],\n",
    "#     'is_addcart': ['sum'],\n",
    "#     'is_order': ['sum']\n",
    "# })\n",
    "# goods14_feat = goods14_feat.reset_index()\n",
    "# goods14_feat.columns = [\n",
    "#     'user_id',\n",
    "#     'goods_id',\n",
    "#     'goods_14clk',\n",
    "#     'goods_14like',\n",
    "#     'goods_14addcart',\n",
    "#     'goods_14order'\n",
    "# ]\n",
    "# goods21_feat= recent21_data.groupby(['user_id', 'goods_id']).agg({\n",
    "#     'is_clk': ['sum'],\n",
    "#     'is_like': ['sum'],\n",
    "#     'is_addcart': ['sum'],\n",
    "#     'is_order': ['sum']\n",
    "# })\n",
    "# goods21_feat = goods21_feat.reset_index()\n",
    "# goods21_feat.columns = [\n",
    "#     'user_id',\n",
    "#     'goods_id',\n",
    "#     'goods_21clk',\n",
    "#     'goods_21like',\n",
    "#     'goods_21addcart',\n",
    "#     'goods_21order'\n",
    "# ]\n",
    "cat7_feat= recent7_data.groupby(['user_id','cat_id']).agg({\n",
    "    'is_clk': ['sum'],\n",
    "    'is_like': ['sum'],\n",
    "    'is_addcart': ['sum'],\n",
    "    'is_order': ['sum']\n",
    "})\n",
    "cat7_feat = cat7_feat.reset_index()\n",
    "cat7_feat.columns = [\n",
    "    'user_id',\n",
    "    'cat_id',\n",
    "    'cat_7clk',\n",
    "    'cat_7like',\n",
    "    'cat_7addcart',\n",
    "    'cat_7order'\n",
    "]\n",
    "# cat14_feat= recent14_data.groupby(['user_id','cat_id']).agg({\n",
    "#     'is_clk': ['sum'],\n",
    "#     'is_like': ['sum'],\n",
    "#     'is_addcart': ['sum'],\n",
    "#     'is_order': ['sum']\n",
    "# })\n",
    "# cat14_feat = cat14_feat.reset_index()\n",
    "# cat14_feat.columns = [\n",
    "#     'user_id',\n",
    "#     'cat_id',\n",
    "#     'cat_14clk',\n",
    "#     'cat_14like',\n",
    "#     'cat_14addcart',\n",
    "#     'cat_14order'\n",
    "# ]\n",
    "# cat21_feat= recent21_data.groupby(['user_id','cat_id']).agg({\n",
    "#     'is_clk': ['sum'],\n",
    "#     'is_like': ['sum'],\n",
    "#     'is_addcart': ['sum'],\n",
    "#     'is_order': ['sum']\n",
    "# })\n",
    "# cat21_feat = cat21_feat.reset_index()\n",
    "# cat21_feat.columns = [\n",
    "#     'user_id',\n",
    "#     'cat_id',\n",
    "#     'cat_21clk',\n",
    "#     'cat_21like',\n",
    "#     'cat_21addcart',\n",
    "#     'cat_21order'\n",
    "# ]\n",
    "\n",
    "brand7_feat= recent7_data.groupby(['user_id','brandsn']).agg({\n",
    "    'is_clk': ['sum'],\n",
    "    'is_like': ['sum'],\n",
    "    'is_addcart': ['sum'],\n",
    "    'is_order': ['sum']\n",
    "})\n",
    "brand7_feat = brand7_feat.reset_index()\n",
    "brand7_feat.columns = [\n",
    "    'user_id',\n",
    "    'brandsn',\n",
    "    'brand_7clk',\n",
    "    'brand_7like',\n",
    "    'brand_7addcart',\n",
    "    'brand_7order'\n",
    "]\n",
    "# brand14_feat= recent14_data.groupby(['user_id','brandsn']).agg({\n",
    "#     'is_clk': ['sum'],\n",
    "#     'is_like': ['sum'],\n",
    "#     'is_addcart': ['sum'],\n",
    "#     'is_order': ['sum']\n",
    "# })\n",
    "# brand14_feat = brand14_feat.reset_index()\n",
    "# brand14_feat.columns = [\n",
    "#     'user_id',\n",
    "#     'brandsn',\n",
    "#     'brand_14clk',\n",
    "#     'brand_14like',\n",
    "#     'brand_14addcart',\n",
    "#     'brand_14order'\n",
    "# ]\n",
    "# brand21_feat= recent21_data.groupby(['user_id','brandsn']).agg({\n",
    "#     'is_clk': ['sum'],\n",
    "#     'is_like': ['sum'],\n",
    "#     'is_addcart': ['sum'],\n",
    "#     'is_order': ['sum']\n",
    "# })\n",
    "# brand21_feat = brand21_feat.reset_index()\n",
    "# brand21_feat.columns = [\n",
    "#     'user_id',\n",
    "#     'brandsn',\n",
    "#     'brand_21clk',\n",
    "#     'brand_21like',\n",
    "#     'brand_21addcart',\n",
    "#     'brand_21order'\n",
    "# ]\n",
    "clicked7_data = recent7_data[recent7_data['is_clk'] > 0]\n",
    "brand7_clk_counts = clicked7_data.groupby('brandsn')['user_id'].nunique()\n",
    "brand7_clk_counts = brand7_clk_counts.reset_index()\n",
    "brand7_clk_counts.columns = [\n",
    "    'brandsn',\n",
    "    'brand_7clk_counts',\n",
    "]\n",
    "like7_data = recent7_data[recent7_data['is_like'] > 0]\n",
    "brand7_like_counts = like7_data.groupby('brandsn')['user_id'].nunique()\n",
    "brand7_like_counts = brand7_like_counts.reset_index()\n",
    "brand7_like_counts.columns = [\n",
    "    'brandsn',\n",
    "    'brand_7like_counts',\n",
    "]\n",
    "addcart7_data = recent7_data[recent7_data['is_addcart'] > 0]\n",
    "brand7_addcart_counts = addcart7_data.groupby('brandsn')['user_id'].nunique()\n",
    "brand7_addcart_counts = brand7_addcart_counts.reset_index()\n",
    "brand7_addcart_counts.columns = [\n",
    "    'brandsn',\n",
    "    'brand_7addcart_counts',\n",
    "]\n",
    "order7_data = recent7_data[recent7_data['is_order'] > 0]\n",
    "brand7_order_counts = order7_data.groupby('brandsn')['user_id'].nunique()\n",
    "brand7_order_counts = brand7_order_counts.reset_index()\n",
    "brand7_order_counts.columns = [\n",
    "    'brandsn',\n",
    "    'brand_7order_counts',\n",
    "]\n",
    "\n",
    "# clicked14_data = recent14_data[recent14_data['is_clk'] > 0]\n",
    "# brand14_clk_counts = clicked14_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand14_clk_counts = brand14_clk_counts.reset_index()\n",
    "# brand14_clk_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_14clk_counts',\n",
    "# ]\n",
    "# like14_data = recent14_data[recent14_data['is_like'] > 0]\n",
    "# brand14_like_counts = like14_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand14_like_counts = brand14_like_counts.reset_index()\n",
    "# brand14_like_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_14like_counts',\n",
    "# ]\n",
    "# addcart14_data = recent14_data[recent14_data['is_addcart'] > 0]\n",
    "# brand14_addcart_counts = addcart14_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand14_addcart_counts = brand14_addcart_counts.reset_index()\n",
    "# brand14_addcart_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_14addcart_counts',\n",
    "# ]\n",
    "# order14_data = recent14_data[recent14_data['is_order'] > 0]\n",
    "# brand14_order_counts = order14_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand14_order_counts = brand14_order_counts.reset_index()\n",
    "# brand14_order_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_14order_counts',\n",
    "# ]\n",
    "\n",
    "# clicked21_data = recent21_data[recent21_data['is_clk'] > 0]\n",
    "# brand21_clk_counts = clicked21_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand21_clk_counts = brand21_clk_counts.reset_index()\n",
    "# brand21_clk_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_21clk_counts',\n",
    "# ]\n",
    "# like21_data = recent21_data[recent21_data['is_like'] > 0]\n",
    "# brand21_like_counts = like21_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand21_like_counts = brand21_like_counts.reset_index()\n",
    "# brand21_like_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_21like_counts',\n",
    "# ]\n",
    "# addcart21_data = recent21_data[recent21_data['is_addcart'] > 0]\n",
    "# brand21_addcart_counts = addcart21_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand21_addcart_counts = brand21_addcart_counts.reset_index()\n",
    "# brand21_addcart_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_21addcart_counts',\n",
    "# ]\n",
    "# order21_data = recent21_data[recent21_data['is_order'] > 0]\n",
    "# brand21_order_counts = order21_data.groupby('brandsn')['user_id'].nunique()\n",
    "# brand21_order_counts = brand21_order_counts.reset_index()\n",
    "# brand21_order_counts.columns = [\n",
    "#     'brandsn',\n",
    "#     'brand_21order_counts',\n",
    "# ]\n",
    "\n",
    "cat7_clk_counts = clicked7_data.groupby('cat_id')['user_id'].nunique()\n",
    "cat7_clk_counts = cat7_clk_counts.reset_index()\n",
    "cat7_clk_counts.columns = [\n",
    "    'cat_id',\n",
    "    'cat_7clk_counts',\n",
    "]\n",
    "\n",
    "cat7_like_counts = like7_data.groupby('cat_id')['user_id'].nunique()\n",
    "cat7_like_counts = cat7_like_counts.reset_index()\n",
    "cat7_like_counts.columns = [\n",
    "    'cat_id',\n",
    "    'cat_7like_counts',\n",
    "]\n",
    "\n",
    "cat7_addcart_counts = addcart7_data.groupby('cat_id')['user_id'].nunique()\n",
    "cat7_addcart_counts = cat7_addcart_counts.reset_index()\n",
    "cat7_addcart_counts.columns = [\n",
    "    'cat_id',\n",
    "    'cat_7addcart_counts',\n",
    "]\n",
    "\n",
    "cat7_order_counts = order7_data.groupby('cat_id')['user_id'].nunique()\n",
    "cat7_order_counts = cat7_order_counts.reset_index()\n",
    "cat7_order_counts.columns = [\n",
    "    'cat_id',\n",
    "    'cat_7order_counts',\n",
    "]\n",
    "\n",
    "#\n",
    "# cat14_clk_counts = clicked14_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat14_clk_counts = cat14_clk_counts.reset_index()\n",
    "# cat14_clk_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_14clk_counts',\n",
    "# ]\n",
    "\n",
    "# cat14_like_counts = like14_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat14_like_counts = cat14_like_counts.reset_index()\n",
    "# cat14_like_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_14like_counts',\n",
    "# ]\n",
    "\n",
    "# cat14_addcart_counts = addcart14_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat14_addcart_counts = cat14_addcart_counts.reset_index()\n",
    "# cat14_addcart_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_14addcart_counts',\n",
    "# ]\n",
    "\n",
    "# cat14_order_counts = order14_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat14_order_counts = cat14_order_counts.reset_index()\n",
    "# cat14_order_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_14order_counts',\n",
    "# ]\n",
    "\n",
    "#\n",
    "# cat21_clk_counts = clicked21_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat21_clk_counts = cat21_clk_counts.reset_index()\n",
    "# cat21_clk_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_21clk_counts',\n",
    "# ]\n",
    "\n",
    "# cat21_like_counts = like21_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat21_like_counts = cat21_like_counts.reset_index()\n",
    "# cat21_like_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_21like_counts',\n",
    "# ]\n",
    "\n",
    "# cat21_addcart_counts = addcart21_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat21_addcart_counts = cat21_addcart_counts.reset_index()\n",
    "# cat21_addcart_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_21addcart_counts',\n",
    "# ]\n",
    "\n",
    "# cat21_order_counts = order21_data.groupby('cat_id')['user_id'].nunique()\n",
    "# cat21_order_counts = cat21_order_counts.reset_index()\n",
    "# cat21_order_counts.columns = [\n",
    "#     'cat_id',\n",
    "#     'cat_21order_counts',\n",
    "# ]\n",
    "\n",
    "data = pd.merge(df,goods7_feat,on=['user_id','goods_id'],how='left')\n",
    "# data = pd.merge(data,goods14_feat,on=['user_id','goods_id'],how='left')\n",
    "# data = pd.merge(data,goods21_feat,on=['user_id','goods_id'],how='left')\n",
    "data = pd.merge(data,cat7_feat,on=['user_id','cat_id'],how='left')\n",
    "# data = pd.merge(data,cat14_feat,on=['user_id','cat_id'],how='left')\n",
    "# data = pd.merge(data,cat21_feat,on=['user_id','cat_id'],how='left')\n",
    "data = pd.merge(data,brand7_feat,on=['user_id','brandsn'],how='left')\n",
    "# data = pd.merge(data,brand14_feat,on=['user_id','brandsn'],how='left')\n",
    "# data = pd.merge(data,brand21_feat,on=['user_id','brandsn'],how='left')\n",
    "\n",
    "data = pd.merge(data,brand7_clk_counts,on=['brandsn'],how='left')\n",
    "data = pd.merge(data,brand7_like_counts,on=['brandsn'],how='left')\n",
    "data = pd.merge(data,brand7_addcart_counts,on=['brandsn'],how='left')\n",
    "data = pd.merge(data,brand7_order_counts,on=['brandsn'],how='left')\n",
    "\n",
    "# data = pd.merge(data,brand14_clk_counts,on=['brandsn'],how='left')\n",
    "# data = pd.merge(data,brand14_like_counts,on=['brandsn'],how='left')\n",
    "# data = pd.merge(data,brand14_addcart_counts,on=['brandsn'],how='left')\n",
    "# data = pd.merge(data,brand14_order_counts,on=['brandsn'],how='left')\n",
    "\n",
    "# data = pd.merge(data,brand21_clk_counts,on=['brandsn'],how='left')\n",
    "# data = pd.merge(data,brand21_like_counts,on=['brandsn'],how='left')\n",
    "# data = pd.merge(data,brand21_addcart_counts,on=['brandsn'],how='left')\n",
    "# data = pd.merge(data,brand21_order_counts,on=['brandsn'],how='left')\n",
    "\n",
    "data = pd.merge(data,cat7_clk_counts,on=['cat_id'],how='left')\n",
    "data = pd.merge(data,cat7_like_counts,on=['cat_id'],how='left')\n",
    "data = pd.merge(data,cat7_addcart_counts,on=['cat_id'],how='left')\n",
    "data = pd.merge(data,cat7_order_counts,on=['cat_id'],how='left')\n",
    "\n",
    "# data = pd.merge(data,cat14_clk_counts,on=['cat_id'],how='left')\n",
    "# data = pd.merge(data,cat14_like_counts,on=['cat_id'],how='left')\n",
    "# data = pd.merge(data,cat14_addcart_counts,on=['cat_id'],how='left')\n",
    "# data = pd.merge(data,cat14_order_counts,on=['cat_id'],how='left')\n",
    "\n",
    "# data = pd.merge(data,cat21_clk_counts,on=['cat_id'],how='left')\n",
    "# data = pd.merge(data,cat21_like_counts,on=['cat_id'],how='left')\n",
    "# data = pd.merge(data,cat21_addcart_counts,on=['cat_id'],how='left')\n",
    "# data = pd.merge(data,cat21_order_counts,on=['cat_id'],how='left')\n",
    "data['is_order'] = data['is_order'].apply(lambda x:1 if x>0 else 0)\n",
    "data.replace(np.nan,0,inplace=True)\n",
    "data.to_csv('data.csv',index=False)\n",
    "# print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T11:52:20.692214Z",
     "iopub.status.busy": "2023-06-11T11:52:20.691548Z",
     "iopub.status.idle": "2023-06-11T11:52:47.624874Z",
     "shell.execute_reply": "2023-06-11T11:52:47.623979Z",
     "shell.execute_reply.started": "2023-06-11T11:52:20.692183Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T11:52:47.658609Z",
     "iopub.status.busy": "2023-06-11T11:52:47.658300Z",
     "iopub.status.idle": "2023-06-11T11:52:49.248862Z",
     "shell.execute_reply": "2023-06-11T11:52:49.247929Z",
     "shell.execute_reply.started": "2023-06-11T11:52:47.658587Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_7_start = '2023-02-25'\n",
    "date_7_end = '2023-03-03'\n",
    "\n",
    "# 筛选出每个商品距离2023.3.4最近的7天的数据\n",
    "mask = (data['date'] >= date_7_start) & (data['date'] <= date_7_end)\n",
    "data = data.loc[mask]\n",
    "data = data.drop(['expose_start_time','cat_id','brandsn','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T11:52:49.251240Z",
     "iopub.status.busy": "2023-06-11T11:52:49.250488Z",
     "iopub.status.idle": "2023-06-11T11:52:51.675567Z",
     "shell.execute_reply": "2023-06-11T11:52:51.674578Z",
     "shell.execute_reply.started": "2023-06-11T11:52:49.251212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# postive_user =  data.groupby('user_id').agg({\n",
    "#     'is_order': 'sum'\n",
    "#     })\n",
    "# postive_user = postive_user.reset_index()\n",
    "# postive_user.columns=[\n",
    "#     'user_id',\n",
    "#     'order_sum',\n",
    "# ]\n",
    "\n",
    "# postive_user = postive_user[postive_user['order_sum']>0]\n",
    "# positive_user = data[data['user_id'].isin(postive_user['user_id'])]\n",
    "# negative_user = data[~data['user_id'].isin(postive_user['user_id'])]\n",
    "\n",
    "\n",
    "test = pd.read_excel('./a榜需要预测的uid_5000.xlsx',names=['user_id'])\n",
    "test = pd.merge(test,data,on=['user_id'])\n",
    "train = data\n",
    "\n",
    "\n",
    "# train = pd.concat([\n",
    "#    positive_user,\n",
    "#    negative_user.sample(int(0.5 * len(negative_user)))\n",
    "# ], axis=0)\n",
    "train1 = train[['is_addcart','goods_7addcart','goods_7order','cat_7order','brand_7order']]\n",
    "test1 = test[['is_addcart','goods_7addcart','goods_7order','cat_7order','brand_7order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T11:52:51.738714Z",
     "iopub.status.busy": "2023-06-11T11:52:51.738391Z",
     "iopub.status.idle": "2023-06-11T11:52:51.794945Z",
     "shell.execute_reply": "2023-06-11T11:52:51.794062Z",
     "shell.execute_reply.started": "2023-06-11T11:52:51.738690Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = np.array(train['is_order'].values)\n",
    "test1 = np.array(test1)\n",
    "train1 = np.array(train1)\n",
    "\n",
    "\n",
    "m1 = int(0.8*len(train1))\n",
    "x_t = train1[:m1,:]\n",
    "y_t = y[:m1]\n",
    "x_t1 = train1[m1:,:]\n",
    "y_t1 = y[m1:]\n",
    "#50 ->0.507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T01:57:35.886385Z",
     "iopub.status.busy": "2023-06-09T01:57:35.885770Z",
     "iopub.status.idle": "2023-06-09T01:57:35.894027Z",
     "shell.execute_reply": "2023-06-09T01:57:35.893217Z",
     "shell.execute_reply.started": "2023-06-09T01:57:35.886346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'goods_id', 'is_clk', 'is_like', 'is_addcart', 'is_order',\n",
       "       'goods_7clk', 'goods_7like', 'goods_7addcart', 'goods_7order',\n",
       "       'cat_7clk', 'cat_7like', 'cat_7addcart', 'cat_7order', 'brand_7clk',\n",
       "       'brand_7like', 'brand_7addcart', 'brand_7order', 'brand_7clk_counts',\n",
       "       'brand_7like_counts', 'brand_7addcart_counts', 'brand_7order_counts',\n",
       "       'cat_7clk_counts', 'cat_7like_counts', 'cat_7addcart_counts',\n",
       "       'cat_7order_counts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-11T11:52:56.428272Z",
     "iopub.status.busy": "2023-06-11T11:52:56.427729Z",
     "iopub.status.idle": "2023-06-11T11:53:02.033245Z",
     "shell.execute_reply": "2023-06-11T11:53:02.032101Z",
     "shell.execute_reply.started": "2023-06-11T11:52:56.428239Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(n_jobs=-1,n_estimators=70)\n",
    "model = randomForest.fit(x_t, y_t)\n",
    "y_pre = model.predict(test1)\n",
    "# accuracy = f1_score(y_t1,y_pre)\n",
    "# print('随机森林',accuracy)\n",
    "\n",
    "\n",
    "# import xgboost as xgb\n",
    "# xgb_classifier = xgb.XGBClassifier(n_jobs=-1,n_estimators=70,max_depth=5,learning_rate=0.1, subsample=0.7, colsample_bytree=0.7)\n",
    "# xgb_classifier.fit(x_t, y_t)\n",
    "# y_pre = xgb_classifier.predict(x_t1)\n",
    "# accuracy = f1_score(y_t1,y_pre)\n",
    "# print('随机森林',accuracy)\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_test1 = {\"n_estimators\":range(1,101,10)}\n",
    "# gsearch1 = GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1),param_grid=param_test1,\n",
    "#                         scoring='f1',cv=10)\n",
    "# gsearch1.fit(train1, y)\n",
    "\n",
    "\n",
    "# means =gsearch1.cv_results_['mean_test_score']\n",
    "# params = gsearch1.cv_results_['params']\n",
    "# for mean,param in zip(means,params):\n",
    "#     print(\"%f  with:   %r\" % (mean,param))\n",
    " \n",
    "\n",
    "# log1 = LogisticRegression(max_iter=500)\n",
    "# model = log1.fit(x_t, y_t)\n",
    "# y_pre = model.predict(x_t1)\n",
    "# accuracy = f1_score(y_t1,y_pre)\n",
    "# print('逻辑回归',accuracy)\n",
    "\n",
    "# decisiontree = DecisionTreeClassifier()\n",
    "# model = decisiontree.fit(x_t, y_t)\n",
    "# y_pre = model.predict(x_t1)\n",
    "# # accuracy = f1_score(y_t1,y_pre)\n",
    "# # print('决策树',accuracy)\n",
    "\n",
    "res = {'user_id':test['user_id'].values,'goods_id':test['goods_id'].values,'order':y_pre}\n",
    "df = pd.DataFrame(res)\n",
    "df = df[df['order']==1]\n",
    "df = df.drop(columns=['order'])\n",
    "df.to_csv('u2i.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T03:51:20.244728Z",
     "iopub.status.busy": "2023-06-09T03:51:20.243690Z",
     "iopub.status.idle": "2023-06-09T03:51:22.108449Z",
     "shell.execute_reply": "2023-06-09T03:51:22.107156Z",
     "shell.execute_reply.started": "2023-06-09T03:51:20.244687Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_clk                   0.061432\r\n",
      "is_like                  0.006996\r\n",
      "is_addcart               0.210836\r\n",
      "is_order                 1.000000\r\n",
      "goods_7clk               0.048860\r\n",
      "goods_7like              0.008831\r\n",
      "goods_7addcart           0.221230\r\n",
      "goods_7order             0.837369\r\n",
      "cat_7clk                -0.009933\r\n",
      "cat_7like               -0.006834\r\n",
      "cat_7addcart             0.045665\r\n",
      "cat_7order               0.252133\r\n",
      "brand_7clk              -0.004443\r\n",
      "brand_7like             -0.004881\r\n",
      "brand_7addcart           0.038105\r\n",
      "brand_7order             0.201963\r\n",
      "brand_7clk_counts       -0.014872\r\n",
      "brand_7like_counts      -0.014143\r\n",
      "brand_7addcart_counts   -0.006075\r\n",
      "brand_7order_counts      0.004669\r\n",
      "cat_7clk_counts         -0.036895\r\n",
      "cat_7like_counts        -0.032912\r\n",
      "cat_7addcart_counts     -0.029478\r\n",
      "cat_7order_counts       -0.021376\r\n",
      "Name: is_order, dtype: float64\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "rc = {'font.sans-serif': 'SimHei',\n",
    "      'axes.unicode_minus': False}\n",
    "corr = train.corr()['is_order']\n",
    "print(corr)\n",
    "# plt.figure()\n",
    "# g1 = sns.heatmap(corr,cmap='cool',annot=True)\n",
    "# g1.set_title('Correlation coefficient matrix for features to features, features to labels')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
